# Database & Cache
MONGO_URI=mongodb://localhost:27017/peer
REDIS_URL=redis://localhost:6379

# App Configuration
API_PORT=3001
UI_PORT=3000

# GitHub Integration
GITHUB_WEBHOOK_SECRET=your_webhook_secret_here
GITHUB_APP_ID=
GITHUB_SECRET=
GITHUB_TOKEN=your_github_token_here

# LLM Providers (Get your free API keys)
# Groq: https://console.groq.com/
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile

# Gemini: https://ai.google.dev/
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-flash
GEMINI_API_BASE=https://generativelanguage.googleapis.com/v1beta/models

# DeepSeek: https://platform.deepseek.com/
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_MODEL=deepseek-coder

# OpenRouter: https://openrouter.ai/ (Access to 100+ models including Mistral, Claude, etc.)
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_MODEL=mistralai/mistral-7b-instruct

# OpenAI (Optional fallback)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini

# LLM Configuration
LLM_PROVIDER=auto
LLM_STRATEGY=full
LLM_TIMEOUT_MS=30000
LLM_CONCURRENCY=3
LLM_DEBUG=1

# Redis Cache Configuration (for LLM response caching)
REDIS_CACHE_ENABLED=true
REDIS_CACHE_TTL=86400
